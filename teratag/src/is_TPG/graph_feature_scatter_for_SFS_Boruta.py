from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import StackingClassifier
import matplotlib.pyplot as plt
import seaborn as sns


#散布図　決定木系　比較
#周波数を選択してください(boruta以外周波数点数　例10個)
fre_num = 28
#borutaの周波数点数
boruta_num = 28
#boruta
name_1 ='Boruta'
#boruta以外
name_2 = 'XGBoost'
name_3 = 'LightGBM'
name_4 = 'CatBoost'
name_5 = 'RandomForest'

# #周波数入力(15個)
# fre_brt = [1.085701497396, 1.097900390625, 1.110099283854, 1.1222981770829998, 1.134497070312, 1.146695963542, 1.207690429687, 1.219889322917, 1.329679361979, 1.341878255208, 1.354077148437, 1.366276041667, 1.378474934896, 1.390673828125, 1.402872721354, 1.415071614583, 1.4272705078119998, 1.4394694010420002, 1.451668294271, 1.4638671875, 1.549259440104, 1.561458333333, 1.573657226562, 1.585856119792, 1.598055013021, 1.61025390625, 1.622452799479, 1.634651692708]
# fre_rand = [1.366276041667, 1.329679361979, 1.097900390625, 1.219889322917, 1.390673828125, 1.1222981770829998, 1.378474934896, 1.451668294271, 1.354077148437, 1.573657226562]
# fre_xgb = [1.219889322917, 1.366276041667, 1.4272705078119998, 1.110099283854, 1.244287109375, 1.146695963542, 1.329679361979, 1.4394694010420002, 1.537060546875, 1.622452799479]
# fre_lgbm = [1.110099283854, 1.219889322917, 1.451668294271, 1.329679361979, 1.634651692708, 1.378474934896, 1.390673828125, 1.207690429687, 1.195491536458, 1.366276041667]
# fre_cat = [1.366276041667, 1.378474934896, 1.329679361979, 1.219889322917, 1.110099283854, 1.451668294271, 1.390673828125, 1.4272705078119998, 1.354077148437, 1.415071614583]

#周波数入力(28個)
fre_brt = [1.085701497396, 1.097900390625, 1.110099283854, 1.1222981770829998, 1.134497070312, 1.146695963542, 1.207690429687, 1.219889322917, 1.329679361979, 1.341878255208, 1.354077148437, 1.366276041667, 1.378474934896, 1.390673828125, 1.402872721354, 1.415071614583, 1.4272705078119998, 1.4394694010420002, 1.451668294271, 1.4638671875, 1.549259440104, 1.561458333333, 1.573657226562, 1.585856119792, 1.598055013021, 1.61025390625, 1.622452799479, 1.634651692708]
fre_rand = [1.366276041667, 1.329679361979, 1.097900390625, 1.219889322917, 1.390673828125, 1.1222981770829998, 1.378474934896, 1.451668294271, 1.354077148437, 1.573657226562, 1.134497070312, 1.110099283854, 1.4394694010420002, 1.4272705078119998, 1.402872721354, 1.085701497396, 1.549259440104, 1.4638671875, 1.561458333333, 1.207690429687, 1.341878255208, 1.585856119792, 1.415071614583, 1.537060546875, 1.0735026041670002, 1.61025390625, 1.31748046875, 1.683447265625]
fre_xgb = [1.219889322917, 1.366276041667, 1.4272705078119998, 1.110099283854, 1.244287109375, 1.146695963542, 1.329679361979, 1.4394694010420002, 1.537060546875, 1.622452799479, 1.500463867187, 1.378474934896, 1.585856119792, 1.4638671875, 1.451668294271, 1.0735026041670002, 1.305281575521, 1.549259440104, 1.000309244792, 1.256486002604, 1.659049479167, 1.476066080729, 1.354077148437, 1.341878255208, 1.097900390625, 1.268684895833, 1.634651692708, 1.049104817708]
fre_lgbm = [1.110099283854, 1.219889322917, 1.451668294271, 1.329679361979, 1.634651692708, 1.378474934896, 1.390673828125, 1.207690429687, 1.195491536458, 1.366276041667, 1.134497070312, 1.31748046875, 1.183292643229, 1.012508138021, 1.415071614583, 1.4272705078119998, 1.573657226562, 1.341878255208, 1.0735026041670002, 1.354077148437, 1.683447265625, 1.244287109375, 1.4638671875, 1.097900390625, 1.585856119792, 1.146695963542, 1.659049479167, 1.232088216146]
fre_cat = [1.366276041667, 1.378474934896, 1.329679361979, 1.219889322917, 1.110099283854, 1.451668294271, 1.390673828125, 1.4272705078119998, 1.354077148437, 1.415071614583, 1.097900390625, 1.402872721354, 1.622452799479, 1.4394694010420002, 1.134497070312, 1.1222981770829998, 1.207690429687, 1.476066080729, 1.573657226562, 1.61025390625, 1.244287109375, 1.341878255208, 1.598055013021, 1.4638671875, 1.31748046875, 1.500463867187, 1.012508138021, 1.146695963542]


x = fre_rand + fre_cat + fre_lgbm + fre_xgb + fre_brt
y = []
y_name = []


for i in range(1,5):
    for j in range(1,fre_num+1):
        y.append(i)

for j in range(1,boruta_num+1):
    y.append(5)
#print(len(y))

for i in range(fre_num):
    y_name.append(name_5)
for i in range(fre_num):
    y_name.append(name_4)
for i in range(fre_num):
    y_name.append(name_3)
for i in range(fre_num):
    y_name.append(name_2)
for i in range(boruta_num):
    y_name.append(name_1)

print(y)
print(y_name)
#print(len(x))
#print(len(y))
#print(len(y_name))

sns.set()
plt.figure(figsize=(10,6))
plt.scatter(x, y, s=100)
plt.title('Frequency Feature Importance', fontsize=20)
plt.xticks([1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7], fontsize=18)
plt.yticks(y ,y_name ,fontsize=18)
# plt.bar(x, y)
plt.xlabel('Frequency[THz]', fontsize=20)
plt.ylabel('Machine Learning Method', fontsize=20)
plt.show()

'''
#散布図　前進法　比較
#周波数を選択してください(boruta以外周波数点数　例10個)
fre_num = 15

#識別器名前
name_1 = 'XGBoost'
name_2 = 'LightGBM'
name_3 = 'CatBoost'
name_4 = 'RandomForest'
name_5 = 'SVM'
name_6 = 'KNN'

#周波数入力
fre_xgb = [1.00030924, 1.01250814, 1.02470703, 1.03690592, 1.04910482, 1.13449707, 1.17109375, 1.18329264, 1.19549154, 1.20769043, 1.24428711, 1.29308268, 1.32967936, 1.37847493, 1.42727051]
fre_lgbm = [1.00030924, 1.01250814, 1.02470703, 1.09790039, 1.13449707, 1.14669596, 1.15889486, 1.19549154, 1.21988932, 1.24428711, 1.32967936, 1.37847493, 1.53706055, 1.65904948, 1.68344727]
fre_cat = [1.01250814, 1.06130371, 1.0735026, 1.0857015, 1.18329264, 1.24428711, 1.31748047, 1.32967936, 1.36627604, 1.39067383, 1.40287272, 1.4394694, 1.57365723, 1.6224528, 1.63465169]
fre_rand = [1.00030924, 1.01250814, 1.03690592, 1.0735026, 1.09790039, 1.12229818, 1.32967936, 1.34187826, 1.36627604, 1.37847493, 1.42727051, 1.46386719, 1.47606608, 1.51266276, 1.58585612]
fre_svm = [1.1222981770829998, 1.195491536458, 1.207690429687, 1.219889322917, 1.232088216146, 1.31748046875, 1.329679361979, 1.354077148437, 1.366276041667, 1.4272705078119998, 1.4882649739579998, 1.500463867187, 1.61025390625, 1.622452799479, 1.634651692708]
fre_knn = [1.13449707, 1.256486, 1.32967936, 1.34187826, 1.35407715, 1.36627604, 1.37847493, 1.39067383, 1.40287272, 1.42727051, 1.4394694, 1.48826497, 1.52486165, 1.64685059, 1.67124837]

x = fre_knn + fre_svm + fre_rand + fre_cat + fre_lgbm + fre_xgb
y = []
y_name = []


for i in range(1,7):
    for j in range(1,fre_num+1):
        y.append(i)

for i in range(fre_num):
    y_name.append(name_6)
for i in range(fre_num):
    y_name.append(name_5)
for i in range(fre_num):
    y_name.append(name_4)
for i in range(fre_num):
    y_name.append(name_3)
for i in range(fre_num):
    y_name.append(name_2)
for i in range(fre_num):
    y_name.append(name_1)

print(y)
print(y_name)
#print(len(x))
#print(len(y))
#print(len(y_name))

sns.set()
plt.figure(figsize=(10,6))
plt.scatter(x, y, s=100)
plt.title('Frequency Feature Importance', fontsize=20)
plt.xticks([1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7], fontsize=18)
plt.yticks(y ,y_name ,fontsize=18)
# plt.bar(x, y)
plt.xlabel('Frequency[THz]', fontsize=20)
plt.ylabel('Machine Learning Method', fontsize=20)
plt.show()
'''


'''
##前進法　棒グラフ　プロット用、周波数を書き込む
frequency_list = [1.00030924, 1.01250814, 1.02470703, 1.03690592, 1.04910482, 1.13449707, 1.17109375, 1.18329264, 1.19549154, 1.20769043, 1.24428711, 1.29308268, 1.32967936, 1.37847493, 1.42727051]

y = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
x = frequency_list

sns.set()
plt.figure(figsize=(10, 5))
plt.bar(x, y, width=0.005, align="center")
plt.title('SFS Feature Importance : XGBoost', fontsize=20)
plt.xticks([1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7], fontsize=18)
plt.yticks(fontsize=18)
# plt.bar(x, y)
plt.xlabel('Frequency[THz]', fontsize=20)
plt.ylabel('feature importance', fontsize=20)
plt.show()
'''


'''
# データの準備
X, y = load_digits(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(
        X,
        y,
        stratify=y,
        random_state=42,
    )

print(X_train)
print(y_train)

# 1段目として、二つのモデルを構築。
# 初期値の max_iter では収束しなかったので大きめの値を設定
estimators = [
        ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),
        ('svr', make_pipeline(
                StandardScaler(),
                LinearSVC(max_iter=4000, random_state=42)
                )
            )
        ]
clf = StackingClassifier(
    estimators=estimators,
    final_estimator=LogisticRegression(max_iter=600),
)
clf.fit(X_train, y_train)
print("正解率:", clf.score(X_test, y_test))
# 正解率: 0.96
'''